{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Logging: Basic Structure and Objects\"\n",
    "date: 2020-10-28\n",
    "type: technical_note\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The [logging module](https://docs.python.org/3/library/logging.html) in Python is a very powerful tool that I've summarily neglected learning until this week. However, as it's often utilized as part of a robust ML pipeline, I finally took the plunge. In this notebook, I'm going to distill the basics I got from the docs, as well as show a simple project that highlights some of the behavior and configuration patterns.\n",
    "\n",
    "## Levels\n",
    "\n",
    "`logging` operates using a concept of \"levels,\" which correspond to varying levels of message-severity. Going from least-severe to most-severe, we have:\n",
    "\n",
    "* `DEBUG`: Super detailed information\n",
    "* `INFO`: Confirmation that thing are working correctly\n",
    "* `WARNING`: Indication that something unexpected happened, but things still work\n",
    "* `ERROR`: Something ran incorrectly in our program\n",
    "* `CRITICAL`: The most serious message. Things severely broken\n",
    "\n",
    "In general, once you set the \"level\" for a `logging` object, it operates at \"that level or more severe\" and ignores all activity lower than it's configured for.\n",
    "\n",
    "For example, if I've got my logging set to `WARNING`, then any time I log with `level='INFO'`, nothing will happen. On the other hand, if I've configured my level to `DEBUG`, then any log of any level will be served.\n",
    "\n",
    "## Objects\n",
    "\n",
    "Generally, there are four base classes that power the library.\n",
    "\n",
    "* `Logger`: Exposes the overall interface\n",
    "* `Handler`: Sends the records created by the `Logger` objects\n",
    "* `Filter`: Determines which logs to output\n",
    "* `Formatter`: Specifies the layout of the `Handler` output\n",
    "\n",
    "Going down the list:\n",
    "\n",
    "### `Logger`\n",
    "\n",
    "The `Logger` object is the one that holds all the other `logging` objects and is the main interface that the client code taps into to leverage the library.\n",
    "\n",
    "You can literally skip all knowledge of intentional instantiation and just do the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.warning('This hit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But I don't think that's a very good decision, because then the lack of output for something like this is confusing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('This also hit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(More on this in a few)\n",
    "\n",
    "Additionally, you can broadly configure your `logging` instance with the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='example.log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this makes things difficult to trace/debug. For instance, `filename='example.log'` suggests that we'll be logging to some file. So why does the following print in standard out?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.warning('This should have written do disk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And no, it didn't both print and write."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cat: example.log: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!cat example.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, I like being more explicit in how I build this out with `getLogger()`. Note, that the docs explicitly say\n",
    "\n",
    ">Note that Loggers should *NEVER* be instantiated directly, but always through the module-level function `logging.getLogger(name)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This hit\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.warning('This hit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, looking at the last few outputs, it should be clear that `WARNING` is the default level that we instantiate with.\n",
    "\n",
    "But what's going on with `root` in the print above?\n",
    "\n",
    "#### Namespaces\n",
    "\n",
    "Like modules, `logging` is namespace-aware.\n",
    "\n",
    "When called with no arguments, as above, `getLogger()` looks to the root of the project and\n",
    "\n",
    "1. Creates a new `Logger` object under `root` if it doesn't exist\n",
    "2. Returns the `root` `Logger` if it does\n",
    "\n",
    "You can also do similar tricks to what you'd do with the `os` or `pathlib` libraries, such as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger __main__ (WARNING)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or calling it with `__file__` (which doesn't work in Notebooks). But the preferred convention is `__name__`.\n",
    "\n",
    "This allows us to leverage clean hierarchical relationships between modules/submodules and their `Logger` objects. For instance, if I've got the line `logging.getLogger(__name__)` in each of my files, then much like imports and modules, there's a clear relationship between the root level `foo`, and the `Logger` objects found in the child `foo.bar` and `foo.bar.baz` submodules. More on this at the end.\n",
    "\n",
    "#### Using the `Logger`\n",
    "\n",
    "We already did a bit of it earlier, but for the sake of completeness, when we log we can either do it generically, specifying the level explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:This is srs bsns\n"
     ]
    }
   ],
   "source": [
    "logger.log(logging.CRITICAL, \"This is srs bsns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or by using the utility functions that correspond to the same name as the level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:This is also srs. But simpler to write\n"
     ]
    }
   ],
   "source": [
    "logger.critical(\"This is also srs. But simpler to write\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Handler`\n",
    "\n",
    "These, unlike the `Logger` are always instantiated directly. Sort of.\n",
    "\n",
    "More accurately, we'll always find ourselves instantiating some *subclass* of the `Handler` object. The two main examples of this are:\n",
    "\n",
    "* `StreamHandler`, which writes to the console/`std.out`\n",
    "* `FileHandler`, which wraps the `open()` function and writes logs to a file\n",
    "\n",
    "There are [a TON of other handlers](https://docs.python.org/3/howto/logging.html#useful-handlers) batteries-included, but for the sake of keeping it simple, these are the only two we'll concern ourselves with.\n",
    "\n",
    "\n",
    "### `Formatter`\n",
    "\n",
    "These provide string formatting for our writes and then some.\n",
    "\n",
    "It's got its own special syntax/keywords for handling, among other things:\n",
    "\n",
    "* Time\n",
    "* File the log was generated in\n",
    "* Line number the long was generated on\n",
    "* Arbitrary messages\n",
    "\n",
    "and [a lot more](https://docs.python.org/3/library/logging.html#logrecord-attributes). We'll see an example of this at the end.\n",
    "\n",
    "### Filter\n",
    "\n",
    "Looks too complicated for our purposes. Maybe another time.\n",
    "\n",
    "\n",
    "## Putting these All Together\n",
    "\n",
    "So now that we know the constituent parts to a logging system, how do we assemble them for use?\n",
    "\n",
    "### Adding `Handler` objects\n",
    "\n",
    "We'll start by making a brand new logger (with an arbitrary name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger = logging.getLogger('new_logger')\n",
    "logger.handlers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting, this totally bare at the start.\n",
    "\n",
    "Then, we'll instantiate a `StreamHandler` object to write to `sys.stdout` and then apply the `addHandler()` method of our `logger`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "stream_info_handler = logging.StreamHandler(sys.stdout)\n",
    "\n",
    "logger.addHandler(stream_info_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking again, we can see that there's now a `StreamHandler` object that meets our definition. The `NOTSET` simply refers to the fact that we haven't specified a level for the `StreamHandler`, and thus, it will defer to however its parent operates-- which again, is `WARNING` by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<StreamHandler stdout (NOTSET)>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.handlers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a little tricky-- why are there two prints?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:new_logger:Boop\n"
     ]
    }
   ],
   "source": [
    "logger.warning('Boop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To investigate this, we'll change the level of our `Handler` object to its most restrictive state, and rerun the `.warning()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_info_handler.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only one print."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:new_logger:Boop\n"
     ]
    }
   ],
   "source": [
    "logger.warning('Boop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is because the `Handler` only fires on `level=50`. Which is code for `CRITICAL`, as specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'CRITICAL'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(stream_info_handler.level)\n",
    "logging.getLevelName(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `logger` itself, however, has an implicit (seemingly-hidden, IMO) writer to `stderr`, at the warning `WARNING` level and above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'WARNING'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(logger.getEffectiveLevel())\n",
    "logging.getLevelName(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still no new `Handler` objects in sight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<StreamHandler stdout (CRITICAL)>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.handlers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, if we overwrite the default behavior, you'll notice that it no longer shows up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "logger.warning(\"This shouldn't hit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding `Formatter` objects\n",
    "\n",
    "The `setFormatter` behaves similarly to the `Logger.addHandler()` method except applies to the `Handler` objects, instead.\n",
    "\n",
    "So we start off by making another fresh `Logger` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('even_newer_logger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll make a simple `StreamHandler` that writes to standard out at a permissive `INTO` level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stream_handler = logging.StreamHandler(sys.stdout)\n",
    "new_stream_handler.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll add the `Handler` to the `Logger`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And we can see that this printed to standard out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:even_newer_logger:And we can see that this printed to standard out\n"
     ]
    }
   ],
   "source": [
    "logger.addHandler(new_stream_handler)\n",
    "\n",
    "logger.warning('And we can see that this printed to standard out')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if we wanted to go back and change the output format of the log generated by the `StreamHandler`, we'd use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-28 18:02:33,042 — even_newer_logger — WARNING — Notice the difference?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:even_newer_logger:Notice the difference?\n"
     ]
    }
   ],
   "source": [
    "FMTR = logging.Formatter(\"%(asctime)s — %(name)s — %(levelname)s —\" \" %(message)s\")\n",
    "\n",
    "new_stream_handler.setFormatter(FMTR)\n",
    "\n",
    "logger.warning('Notice the difference?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Final Note on Inheritence\n",
    "\n",
    "[The docs have a great image to elucidate further](https://docs.python.org/3/howto/logging.html#logging-flow), but I wanted to illustrate how level-inheritence works in `logging`.\n",
    "\n",
    "Basically, there are two general rules that are followed:\n",
    "\n",
    "1. If a `Logger` is initialized in some submodule (e.g. `foo.bar`), if you don't specify the level, it will look to the parent (`foo`) to see if *it* has a declared level. If it doesn't find it there, then it will look higher and higher until it finds `root`, which will either be declared, or set to `WARNING`, by default.\n",
    "\n",
    "2. When calling `logger.log()` with any arbitrary level, if the call isn't more severe than the `logger` level, it won't get passed down to any of its `Handler` objects, even if *those* accept that severity.\n",
    "\n",
    "To illustrate that second point, we'll make a new `Logger` that only accepts `CRITICAL`, and give it a `StreamHandler` that will accept `DEBUG`, and therefore everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "firewall = logging.getLogger('firewall')\n",
    "firewall.setLevel(logging.CRITICAL)\n",
    "\n",
    "easygoing_stream_handler = logging.StreamHandler(sys.stdout)\n",
    "easygoing_stream_handler.setLevel(logging.DEBUG)\n",
    "\n",
    "firewall.addHandler(easygoing_stream_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll make a simple `.info()` call that doesn't call the `StreamHandler`, whatsoever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "firewall.info('Alas, this was blocked.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning up our environment for the next section\n",
    "\n",
    "del (FMTR, logger, easygoing_stream_handler,\n",
    "     stream_info_handler, firewall, new_stream_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Project\n",
    "\n",
    "To tie these concepts together, I liked how [this repo](https://github.com/trainindata/deploying-machine-learning-models) structured their logging and structured a dummy project that highlights the most essential aspects of their setup.\n",
    "\n",
    "Say we've got some module, `app`, that we want to run via `main.py` to generate some logs into the `logs` directory.\n",
    "\n",
    "```\n",
    "simple_logging\n",
    "|   main.py\n",
    "|\n",
    "+---app\n",
    "|   |   app_code.py\n",
    "|   |   __init__.py\n",
    "|   |\n",
    "|   \\---config\n",
    "|           logging_config.py\n",
    "|\n",
    "\\---logs\n",
    "```\n",
    "\n",
    "### Files\n",
    "\n",
    "`main.py` is super straight-forward.\n",
    "\n",
    "``` python\n",
    "from app.app_code import run_app\n",
    "\n",
    "run_app()\n",
    "```\n",
    "\n",
    "`app/app_code.py` contains our app. The goal here is to log each `App ran for X` to a log file, but *print* the `i=6` case to the console.\n",
    "\n",
    "``` python\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "print(__name__, 'printed from', __file__)\n",
    "\n",
    "def run_app():\n",
    "    for i in range(10):\n",
    "        logger.info(f\"App ran for {i}\")\n",
    "\n",
    "        if i == 6:\n",
    "            logger.warn(\"We saw the number 6!\")\n",
    "```\n",
    "\n",
    "The fact that we want to have two different log outputs should be a dead giveaway that we want to leverage both a `StreamHandler` and a `FileHandler`. Which is precisely what we specify in `app/config/logging_config.py`\n",
    "\n",
    "``` python\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "FORMATTER = logging.Formatter(\n",
    "    \"%(asctime)s — %(name)s — %(levelname)s —\" \"%(funcName)s:%(lineno)d — %(message)s\"\n",
    ")\n",
    "\n",
    "def get_console_handler():\n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setFormatter(FORMATTER)\n",
    "    console_handler.setLevel(logging.WARNING)\n",
    "    return console_handler\n",
    "\n",
    "\n",
    "def get_file_handler():\n",
    "    file_handler = logging.FileHandler(\"logs/app.log\")\n",
    "    file_handler.setFormatter(FORMATTER)\n",
    "    file_handler.setLevel(logging.INFO)\n",
    "    return file_handler\n",
    "```\n",
    "\n",
    "\n",
    "I'm not sure if the `get___()` functions above are convention or not, but I really liked how clean it looked in the implementation, so I'm copying it here.\n",
    "\n",
    "These functions are imported to `app/__init__.py`, where we define the `app`-level `Logger` object.\n",
    "\n",
    "``` python\n",
    "import logging\n",
    "\n",
    "from app.config import logging_config\n",
    "\n",
    "print(__name__, 'printed from', __file__)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "logger.addHandler(logging_config.get_console_handler())\n",
    "logger.addHandler(logging_config.get_file_handler())\n",
    "```\n",
    "\n",
    "### In Action\n",
    "\n",
    "So when you consider the call stack of running `main.py`, the first thing to execute is `from app.app_code import run_app`. Recall from [our notebook on Packages](https://napsterinblue.github.io/notes/python/development/packages/) that the `__init__.py` in the root of the module is the first thing that gets executed. Here, that's `app/__init__.py`.\n",
    "\n",
    "In *that* file, we `import logging`. Easy enough. Then on line 3 we execute `from app.config import logging config`, which means we jump into `app/config/logging_config.py`. This file executes top to bottom, defining our `logging.Formatter`, `FORMATTER`, and stuffing it into the two `get____` functions.\n",
    "\n",
    "Once that's done running, the functions get passed back to `app/__init__.py`, and are both executed. This creates both `Handler` subclasses, which are added to the `Logger`.\n",
    "\n",
    "So let me stop with this wall of text and ask: What gets passed back after `app/__init__.py` runs?\n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "Nothing... Sort of.\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "Before we run the whole thing, let's just see what happens when we import `simple_logging.app`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    os.remove('simple_logging/logs/app.log')\n",
    "except FileNotFoundError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change into the same directory as `main.py` for\n",
    "# same behavior\n",
    "os.chdir('simple_logging')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the `Logger` instantiated in `app/__init__.py` comes before the one in `app/app_code.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<StreamHandler stderr (NOTSET)>]\n",
      "__name__ app.app_code    printed from app/app_code.py\n",
      "__name__ app             printed from app/__init__.py\n"
     ]
    }
   ],
   "source": [
    "from app.app_code import run_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But there don't appear to be any artifacts created from their run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable   Type        Data/Info\n",
      "--------------------------------\n",
      "logging    module      <module 'logging' from 'C<...>b\\\\logging\\\\__init__.py'>\n",
      "os         module      <module 'os' from 'C:\\\\Us<...>\\\\anaconda3\\\\lib\\\\os.py'>\n",
      "run_app    function    <function run_app at 0x0000023BB8EDA8B8>\n",
      "sys        module      <module 'sys' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if you know where to look, you can find them. For this, we'll dig into the `logging` namespace and find the dictionary of all active loggers.\n",
    "\n",
    "There are a lot of them. A lot of which are a product of writing this post in a Jupyter Notebook.\n",
    "\n",
    "But you'll also notice that the `Logger` objects that we blew away, up above, are still here (`new_logger`, `firewall`, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['concurrent.futures', 'concurrent', 'asyncio', 'prompt_toolkit', 'parso.python.diff', 'parso.python', 'parso', 'parso.cache', 'tornado.access', 'tornado', 'tornado.application', 'tornado.general', 'IPKernelApp', '__main__', 'new_logger', 'even_newer_logger', 'firewall', 'app.app_code', 'app'])\n"
     ]
    }
   ],
   "source": [
    "print(logging.Logger.manager.loggerDict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is because, critically, **the `logging` module hangs onto every object created-- unless forced otherwise-- for the duration of the program being run**. So nothing is *returned* when we walked through all of the `__init__` code, but we added our user-defined `Logger` instances to the `logging` module itself.\n",
    "\n",
    "Let's go ahead and clean these up..."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hidden_loggers = list(logging.Logger.manager.loggerDict.keys())\n",
    "\n",
    "for logger_key in hidden_loggers:\n",
    "    if logger_key not in ['app', 'app.app_code']:\n",
    "        del logging.Logger.manager.loggerDict[logger_key]\n",
    "\n",
    "logging.Logger.manager.loggerDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows us to cherry-pick the objects that got created from the `import` statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_logger = logging.Logger.manager.loggerDict['app']\n",
    "app__app_code_logger = logging.Logger.manager.loggerDict['app.app_code']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as you can see, because we created the `app` `Logger` first, and because `app.app_code` inherits from its parent class (unless specified) both `Logger` objects are of `level='DEBUG'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger app (DEBUG)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger app.app_code (DEBUG)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app__app_code_logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actually Running the Code\n",
    "\n",
    "However, if you look our `app/config/logging_config.py` you'll notice that the `get_console_handler()` and `get_file_handler()` functions both explicitly overwrite the loose strictness of the `Logger` they're assigned to.\n",
    "\n",
    "* The `StreamHandler` is set to `WARNING`\n",
    "* The `FileHandler` is set to `INFO`\n",
    "\n",
    "In practice, it means that when we execute `run_app()`, we expect to see 10 `INFO` logs written to our logfile location, and 1 `WARNING` message, printed to the terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clearing the fallback Logger for the logging module.\n",
    "# the un-instantiated stuff we did up top made a \n",
    "# tricky, hidden logger that wrote to standard out, in\n",
    "# addition to the loggers we actually want. Made for gross\n",
    "# notebook output. Signed, I've been debugging this for 3 hrs.\n",
    "logging.root.handlers = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's our one `WARNING`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-28 18:02:33,117 — app.app_code — WARNING —run_app:13 — We saw the number 6!\n"
     ]
    }
   ],
   "source": [
    "%run main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and here's 10 logged records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-28 18:02:33,116 — app.app_code — INFO —run_app:10 — App ran for 0\n",
      "2020-10-28 18:02:33,116 — app.app_code — INFO —run_app:10 — App ran for 1\n",
      "2020-10-28 18:02:33,116 — app.app_code — INFO —run_app:10 — App ran for 2\n",
      "2020-10-28 18:02:33,116 — app.app_code — INFO —run_app:10 — App ran for 3\n",
      "2020-10-28 18:02:33,116 — app.app_code — INFO —run_app:10 — App ran for 4\n",
      "2020-10-28 18:02:33,116 — app.app_code — INFO —run_app:10 — App ran for 5\n",
      "2020-10-28 18:02:33,116 — app.app_code — INFO —run_app:10 — App ran for 6\n",
      "2020-10-28 18:02:33,117 — app.app_code — WARNING —run_app:13 — We saw the number 6!\n",
      "2020-10-28 18:02:33,117 — app.app_code — INFO —run_app:10 — App ran for 7\n",
      "2020-10-28 18:02:33,117 — app.app_code — INFO —run_app:10 — App ran for 8\n",
      "2020-10-28 18:02:33,117 — app.app_code — INFO —run_app:10 — App ran for 9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('logs/app.log', 'r') as f:\n",
    "    print(f.read())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
