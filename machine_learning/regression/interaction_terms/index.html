<!DOCTYPE html>
<html lang="en">

<head>

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-66582-32"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-66582-32');
    </script>

    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<meta property="og:title" content="Interaction Terms in Python" />
<meta property="og:description" content="Vanilla OLS Say we&rsquo;ve got a dataset
from warnings import filterwarnings filterwarnings(&#39;ignore&#39;)from yellowbrick.datasets import load_bikeshare X, y = load_bikeshare() Where we measure the number of DC-area bikes rented
y.head() 0 16 1 40 2 32 3 13 4 1 Name: riders, dtype: int64  Based on a number of features
X.head()  .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    season year month hour holiday weekday workingday weather temp feelslike humidity windspeed     0 1 0 1 0 0 6 0 1 0." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://napsterinblue.github.io/notes/machine_learning/regression/interaction_terms/" />



<meta property="article:published_time" content="2019-09-11T00:00:00&#43;00:00"/>

<meta property="article:modified_time" content="2019-09-11T00:00:00&#43;00:00"/>











<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Interaction Terms in Python"/>
<meta name="twitter:description" content="Vanilla OLS Say we&rsquo;ve got a dataset
from warnings import filterwarnings filterwarnings(&#39;ignore&#39;)from yellowbrick.datasets import load_bikeshare X, y = load_bikeshare() Where we measure the number of DC-area bikes rented
y.head() 0 16 1 40 2 32 3 13 4 1 Name: riders, dtype: int64  Based on a number of features
X.head()  .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    season year month hour holiday weekday workingday weather temp feelslike humidity windspeed     0 1 0 1 0 0 6 0 1 0."/>
<meta name="generator" content="Hugo 0.40.3" />

    
<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BlogPosting",
  "headline": "Interaction Terms in Python",
  "url": "https://napsterinblue.github.io/notes/machine_learning/regression/interaction_terms/",
  "wordCount": "2339",
  "datePublished": "2019-09-11T00:00:00&#43;00:00",
  "dateModified": "2019-09-11T00:00:00&#43;00:00",
  "author": {
    "@type": "Person",
    "name": ""
  }
}
</script> 

    <title>Interaction Terms in Python</title>

    
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/css/bootstrap.min.css" integrity="sha384-PsH8R72JQ3SOdhVi3uxftmaW6Vc51MKb0q5P2rRUpPvrszuE4W1povHYgTpBfshb"
        crossorigin="anonymous">

    
    <link href="https://napsterinblue.github.io/notes/css/custom.css" rel="stylesheet">
    <link href="https://napsterinblue.github.io/notes/css/syntax.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Muli:400,500,700" rel="stylesheet">

    <link href="" rel="alternate" type="application/rss+xml" title="Data Science Notes" />

    <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[','\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre','code'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});
</script>

</head>

<body>

    <nav class="navbar navbar-expand-sm fixed-top">
        <div class="container-fluid">
            <a class="navbar-brand" href="https://napsterinblue.github.io">Movies, Metrics, Musings</a>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent"
                aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>

            <div class="collapse navbar-collapse" id="navbarSupportedContent">
                <ul class="nav navbar-nav mr-auto"></ul>
                <ul class="nav navbar-nav">
                    <li><a href="https://napsterinblue.github.io/pages/about.html" title="About">About</a></li>
                    <li><a href="https://napsterinblue.github.io/archives.html" title="Archive">Archive</a></li>
                    <li><a href="https://napsterinblue.github.io/pages/resources.html" title="Resources">Resources</a></li>
                    <li><a href="https://napsterinblue.github.io/notes/" title="Notes">My Notes</a></li>

                </ul>
            </div>
        </div>
    </nav>


    
    <div class="container">
        <div class="row">
            <div class="col-sm-12">

                 


<article>
  <div class="technical_note">
  <header>
    <h1 class="technical_note_title">Interaction Terms in Python</h1>
    <div class="technical_note_date">
      <time datetime=" 2019-09-11T00:00:00Z "> 11 Sep 2019</time>
    </div>
  </header>
  <div class="content">
  

<h2 id="vanilla-ols">Vanilla OLS</h2>

<p>Say we&rsquo;ve got a dataset</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">warnings</span> <span class="kn">import</span> <span class="n">filterwarnings</span>
<span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span></code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">yellowbrick.datasets</span> <span class="kn">import</span> <span class="n">load_bikeshare</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_bikeshare</span><span class="p">()</span></code></pre></div>
<p>Where we measure the number of DC-area bikes rented</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">y</span><span class="o">.</span><span class="n">head</span><span class="p">()</span></code></pre></div>
<pre><code>0    16
1    40
2    32
3    13
4     1
Name: riders, dtype: int64
</code></pre>

<p>Based on a number of features</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">X</span><span class="o">.</span><span class="n">head</span><span class="p">()</span></code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>season</th>
      <th>year</th>
      <th>month</th>
      <th>hour</th>
      <th>holiday</th>
      <th>weekday</th>
      <th>workingday</th>
      <th>weather</th>
      <th>temp</th>
      <th>feelslike</th>
      <th>humidity</th>
      <th>windspeed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>6</td>
      <td>0</td>
      <td>1</td>
      <td>0.24</td>
      <td>0.2879</td>
      <td>0.81</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>6</td>
      <td>0</td>
      <td>1</td>
      <td>0.22</td>
      <td>0.2727</td>
      <td>0.80</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
      <td>6</td>
      <td>0</td>
      <td>1</td>
      <td>0.22</td>
      <td>0.2727</td>
      <td>0.80</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>3</td>
      <td>0</td>
      <td>6</td>
      <td>0</td>
      <td>1</td>
      <td>0.24</td>
      <td>0.2879</td>
      <td>0.75</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>4</td>
      <td>0</td>
      <td>6</td>
      <td>0</td>
      <td>1</td>
      <td>0.24</td>
      <td>0.2879</td>
      <td>0.75</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div>

<p>And just shoving everything into a Logistic Regression seems to work&hellip; alright</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">statsmodels.api</span> <span class="kn">import</span> <span class="n">OLS</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="kn">as</span> <span class="nn">sm</span>

<span class="n">X_const</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">X_const</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span></code></pre></div>
<p><table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>         <td>riders</td>      <th>  R-squared:         </th>  <td>   0.389</td><br />
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.388</td><br />
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   920.8</td><br />
</tr>
<tr>
  <th>Date:</th>             <td>Thu, 12 Sep 2019</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td><br />
</tr>
<tr>
  <th>Time:</th>                 <td>12:39:26</td>     <th>  Log-Likelihood:    </th> <td>-1.1076e+05</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td> 17379</td>      <th>  AIC:               </th>  <td>2.216e+05</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td> 17366</td>      <th>  BIC:               </th>  <td>2.217e+05</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>    12</td>      <th>                     </th>      <td> </td><br />
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td><br />
</tr>
</table>
<table class="simpletable">
<tr>
       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P&gt;|t|</th>  <th>[0.025</th>    <th>0.975]</th><br />
</tr>
<tr>
  <th>const</th>      <td>  -25.7573</td> <td>    7.057</td> <td>   -3.650</td> <td> 0.000</td> <td>  -39.590</td> <td>  -11.925</td>
</tr>
<tr>
  <th>season</th>     <td>   19.8993</td> <td>    1.819</td> <td>   10.941</td> <td> 0.000</td> <td>   16.334</td> <td>   23.464</td>
</tr>
<tr>
  <th>year</th>       <td>   81.0872</td> <td>    2.164</td> <td>   37.463</td> <td> 0.000</td> <td>   76.845</td> <td>   85.330</td>
</tr>
<tr>
  <th>month</th>      <td>   -0.0086</td> <td>    0.567</td> <td>   -0.015</td> <td> 0.988</td> <td>   -1.120</td> <td>    1.103</td>
</tr>
<tr>
  <th>hour</th>       <td>    7.6706</td> <td>    0.165</td> <td>   46.513</td> <td> 0.000</td> <td>    7.347</td> <td>    7.994</td>
</tr>
<tr>
  <th>holiday</th>    <td>  -21.8792</td> <td>    6.694</td> <td>   -3.268</td> <td> 0.001</td> <td>  -35.001</td> <td>   -8.758</td>
</tr>
<tr>
  <th>weekday</th>    <td>    1.8784</td> <td>    0.541</td> <td>    3.474</td> <td> 0.001</td> <td>    0.819</td> <td>    2.938</td>
</tr>
<tr>
  <th>workingday</th> <td>    3.9392</td> <td>    2.396</td> <td>    1.644</td> <td> 0.100</td> <td>   -0.756</td> <td>    8.635</td>
</tr>
<tr>
  <th>weather</th>    <td>   -3.4321</td> <td>    1.905</td> <td>   -1.802</td> <td> 0.072</td> <td>   -7.165</td> <td>    0.301</td>
</tr>
<tr>
  <th>temp</th>       <td>   78.1498</td> <td>   36.957</td> <td>    2.115</td> <td> 0.034</td> <td>    5.710</td> <td>  150.590</td>
</tr>
<tr>
  <th>feelslike</th>  <td>  233.1571</td> <td>   41.517</td> <td>    5.616</td> <td> 0.000</td> <td>  151.779</td> <td>  314.535</td>
</tr>
<tr>
  <th>humidity</th>   <td> -198.1847</td> <td>    6.889</td> <td>  -28.770</td> <td> 0.000</td> <td> -211.687</td> <td> -184.682</td>
</tr>
<tr>
  <th>windspeed</th>  <td>   41.5652</td> <td>    9.628</td> <td>    4.317</td> <td> 0.000</td> <td>   22.692</td> <td>   60.438</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>3417.855</td> <th>  Durbin-Watson:     </th> <td>   0.553</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>6659.872</td>
</tr>
<tr>
  <th>Skew:</th>           <td> 1.198</td>  <th>  Prob(JB):          </th> <td>    0.00</td>
</tr>
<tr>
  <th>Kurtosis:</th>       <td> 4.859</td>  <th>  Cond. No.          </th> <td>    787.</td>
</tr>
</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</p>

<p>But at the same time, have good reason to believe that there&rsquo;s some colinearity/interaction at play with our features.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">yellowbrick.features</span> <span class="kn">import</span> <span class="n">Rank2D</span>

<span class="n">visualizer</span> <span class="o">=</span> <span class="n">Rank2D</span><span class="p">(</span><span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;pearson&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">600</span><span class="p">,</span> <span class="mi">500</span><span class="p">))</span>
<span class="n">visualizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">visualizer</span><span class="o">.</span><span class="n">poof</span><span class="p">();</span></code></pre></div>
<pre><code>C:\Users\Nick\Anaconda3\lib\site-packages\yellowbrick\features\rankd.py:215: YellowbrickWarning: RankD plots may be clipped when using matplotlib v3.1.1, upgrade to matplotlib v3.1.2 or later to fix the plots.
  warnings.warn(msg, YellowbrickWarning)
</code></pre>

<p><img src="interaction_terms_12_1.png" alt="png" /></p>

<h2 id="interaction-terms">Interaction Terms</h2>

<p>From here, a good data scientist will take the time to do exploratory analysis and thoughtful feature engineering&ndash; this is the &ldquo;More Art than Science&rdquo; adage you hear so often.</p>

<p>But we&rsquo;re trying to be home by 5, so how do we cram everything in and see what shakes out?</p>

<h3 id="getting-values">Getting Values</h3>

<p>Thankfully, the <code>PolynomialFeatures</code> object in <code>sklearn</code> has us mostly-covered.</p>

<p>It&rsquo;s originally used to generate sequences of <code>(b_i1 * x_i) + (b_i2 * x_i^2) + ...</code> for each feature in <code>X</code>, taking us from <code>n</code> features to <code>2^n</code> features (in the case of <code>PolynomialFeatures(degree=2)</code>, anyhow).</p>

<p>We&rsquo;re not interested in polynomials, per se, but if you squint, the same <code>itertools</code> magic™ that powers the backend of this can also be used to provide all pairwise feature combinations, with minimal rewriting. They provide this, ez pz, with the <code>interaction_only</code> flag.</p>

<p>And so we go from</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">X</span><span class="o">.</span><span class="n">shape</span></code></pre></div>
<pre><code>(17379, 12)
</code></pre>

<p>To an expected $\frac{p * (p - 1)}{2}$ pairs, plus our original <code>p</code> features, plus a bias term</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">p</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="p">(</span><span class="n">p</span> <span class="o">*</span> <span class="p">(</span><span class="n">p</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">p</span> <span class="o">+</span> <span class="mi">1</span></code></pre></div>
<pre><code>79.0
</code></pre>

<p>Coolio</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>

<span class="n">interaction</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">interaction_only</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">include_bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">X_inter</span> <span class="o">=</span> <span class="n">interaction</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">X_inter_const</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">X_inter</span><span class="p">)</span>

<span class="n">X_inter_const</span><span class="o">.</span><span class="n">shape</span></code></pre></div>
<pre><code>(17379, 79)
</code></pre>

<p>Now we brazenly throw it into a new model, and&hellip; oh. A lot of features called <code>x</code></p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">model</span> <span class="o">=</span> <span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">X_inter_const</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span></code></pre></div>
<p><table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>         <td>riders</td>      <th>  R-squared:         </th>  <td>   0.449</td><br />
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.447</td><br />
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   183.2</td><br />
</tr>
<tr>
  <th>Date:</th>             <td>Thu, 12 Sep 2019</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td><br />
</tr>
<tr>
  <th>Time:</th>                 <td>12:39:26</td>     <th>  Log-Likelihood:    </th> <td>-1.0986e+05</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td> 17379</td>      <th>  AIC:               </th>  <td>2.199e+05</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td> 17301</td>      <th>  BIC:               </th>  <td>2.205e+05</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>    77</td>      <th>                     </th>      <td> </td><br />
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td><br />
</tr>
</table>
<table class="simpletable">
<tr>
    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P&gt;|t|</th>  <th>[0.025</th>    <th>0.975]</th><br />
</tr>
<tr>
  <th>const</th> <td>  -12.9215</td> <td>   31.348</td> <td>   -0.412</td> <td> 0.680</td> <td>  -74.367</td> <td>   48.524</td>
</tr>
<tr>
  <th>x1</th>    <td>    4.8668</td> <td>   13.591</td> <td>    0.358</td> <td> 0.720</td> <td>  -21.773</td> <td>   31.506</td>
</tr>
<tr>
  <th>x2</th>    <td>    1.5025</td> <td>   13.709</td> <td>    0.110</td> <td> 0.913</td> <td>  -25.368</td> <td>   28.373</td>
</tr>
<tr>
  <th>x3</th>    <td>   -5.6567</td> <td>    3.650</td> <td>   -1.550</td> <td> 0.121</td> <td>  -12.811</td> <td>    1.497</td>
</tr>
<tr>
  <th>x4</th>    <td>   -1.5711</td> <td>    1.010</td> <td>   -1.555</td> <td> 0.120</td> <td>   -3.551</td> <td>    0.409</td>
</tr>
<tr>
  <th>x5</th>    <td>  -53.5016</td> <td>   42.280</td> <td>   -1.265</td> <td> 0.206</td> <td> -136.374</td> <td>   29.371</td>
</tr>
<tr>
  <th>x6</th>    <td>   -5.8416</td> <td>    3.221</td> <td>   -1.814</td> <td> 0.070</td> <td>  -12.155</td> <td>    0.471</td>
</tr>
<tr>
  <th>x7</th>    <td>  -59.3405</td> <td>   14.670</td> <td>   -4.045</td> <td> 0.000</td> <td>  -88.095</td> <td>  -30.586</td>
</tr>
<tr>
  <th>x8</th>    <td>   24.8815</td> <td>   12.260</td> <td>    2.030</td> <td> 0.042</td> <td>    0.851</td> <td>   48.912</td>
</tr>
<tr>
  <th>x9</th>    <td>  967.3801</td> <td>  242.465</td> <td>    3.990</td> <td> 0.000</td> <td>  492.123</td> <td> 1442.637</td>
</tr>
<tr>
  <th>x10</th>   <td> -398.7968</td> <td>  267.389</td> <td>   -1.491</td> <td> 0.136</td> <td> -922.906</td> <td>  125.313</td>
</tr>
<tr>
  <th>x11</th>   <td>   29.5847</td> <td>   38.027</td> <td>    0.778</td> <td> 0.437</td> <td>  -44.953</td> <td>  104.122</td>
</tr>
<tr>
  <th>x12</th>   <td> -174.6887</td> <td>   55.839</td> <td>   -3.128</td> <td> 0.002</td> <td> -284.138</td> <td>  -65.239</td>
</tr>
<tr>
  <th>x13</th>   <td>   -2.0902</td> <td>    3.782</td> <td>   -0.553</td> <td> 0.580</td> <td>   -9.503</td> <td>    5.322</td>
</tr>
<tr>
  <th>x14</th>   <td>    1.9024</td> <td>    0.528</td> <td>    3.600</td> <td> 0.000</td> <td>    0.867</td> <td>    2.938</td>
</tr>
<tr>
  <th>x15</th>   <td>    0.7962</td> <td>    0.259</td> <td>    3.071</td> <td> 0.002</td> <td>    0.288</td> <td>    1.304</td>
</tr>
<tr>
  <th>x16</th>   <td>   10.7146</td> <td>    8.522</td> <td>    1.257</td> <td> 0.209</td> <td>   -5.990</td> <td>   27.419</td>
</tr>
<tr>
  <th>x17</th>   <td>    0.8804</td> <td>    0.890</td> <td>    0.989</td> <td> 0.323</td> <td>   -0.864</td> <td>    2.625</td>
</tr>
<tr>
  <th>x18</th>   <td>   -3.3540</td> <td>    3.979</td> <td>   -0.843</td> <td> 0.399</td> <td>  -11.152</td> <td>    4.444</td>
</tr>
<tr>
  <th>x19</th>   <td>    5.1034</td> <td>    3.100</td> <td>    1.646</td> <td> 0.100</td> <td>   -0.972</td> <td>   11.179</td>
</tr>
<tr>
  <th>x20</th>   <td> -224.2428</td> <td>   86.181</td> <td>   -2.602</td> <td> 0.009</td> <td> -393.166</td> <td>  -55.320</td>
</tr>
<tr>
  <th>x21</th>   <td>  175.4640</td> <td>   94.973</td> <td>    1.848</td> <td> 0.065</td> <td>  -10.693</td> <td>  361.621</td>
</tr>
<tr>
  <th>x22</th>   <td>  -20.6737</td> <td>   12.747</td> <td>   -1.622</td> <td> 0.105</td> <td>  -45.659</td> <td>    4.312</td>
</tr>
<tr>
  <th>x23</th>   <td>   27.4909</td> <td>   16.320</td> <td>    1.685</td> <td> 0.092</td> <td>   -4.497</td> <td>   59.479</td>
</tr>
<tr>
  <th>x24</th>   <td>    2.0389</td> <td>    1.193</td> <td>    1.709</td> <td> 0.087</td> <td>   -0.299</td> <td>    4.377</td>
</tr>
<tr>
  <th>x25</th>   <td>    2.7809</td> <td>    0.318</td> <td>    8.752</td> <td> 0.000</td> <td>    2.158</td> <td>    3.404</td>
</tr>
<tr>
  <th>x26</th>   <td>  -10.2711</td> <td>   13.890</td> <td>   -0.739</td> <td> 0.460</td> <td>  -37.497</td> <td>   16.955</td>
</tr>
<tr>
  <th>x27</th>   <td>    3.0712</td> <td>    1.047</td> <td>    2.932</td> <td> 0.003</td> <td>    1.018</td> <td>    5.124</td>
</tr>
<tr>
  <th>x28</th>   <td>   18.9473</td> <td>    4.631</td> <td>    4.092</td> <td> 0.000</td> <td>    9.870</td> <td>   28.024</td>
</tr>
<tr>
  <th>x29</th>   <td>    1.8761</td> <td>    3.686</td> <td>    0.509</td> <td> 0.611</td> <td>   -5.349</td> <td>    9.101</td>
</tr>
<tr>
  <th>x30</th>   <td> -157.1947</td> <td>   81.641</td> <td>   -1.925</td> <td> 0.054</td> <td> -317.219</td> <td>    2.830</td>
</tr>
<tr>
  <th>x31</th>   <td>  281.8987</td> <td>   91.747</td> <td>    3.073</td> <td> 0.002</td> <td>  102.066</td> <td>  461.731</td>
</tr>
<tr>
  <th>x32</th>   <td>  -86.9838</td> <td>   13.435</td> <td>   -6.475</td> <td> 0.000</td> <td> -113.317</td> <td>  -60.650</td>
</tr>
<tr>
  <th>x33</th>   <td>   56.9213</td> <td>   18.839</td> <td>    3.021</td> <td> 0.003</td> <td>   19.995</td> <td>   93.848</td>
</tr>
<tr>
  <th>x34</th>   <td>   -0.1121</td> <td>    0.081</td> <td>   -1.390</td> <td> 0.165</td> <td>   -0.270</td> <td>    0.046</td>
</tr>
<tr>
  <th>x35</th>   <td>   -2.2869</td> <td>    2.442</td> <td>   -0.937</td> <td> 0.349</td> <td>   -7.073</td> <td>    2.499</td>
</tr>
<tr>
  <th>x36</th>   <td>   -0.2278</td> <td>    0.277</td> <td>   -0.823</td> <td> 0.410</td> <td>   -0.770</td> <td>    0.314</td>
</tr>
<tr>
  <th>x37</th>   <td>    1.5086</td> <td>    1.241</td> <td>    1.215</td> <td> 0.224</td> <td>   -0.924</td> <td>    3.942</td>
</tr>
<tr>
  <th>x38</th>   <td>   -0.1445</td> <td>    0.980</td> <td>   -0.147</td> <td> 0.883</td> <td>   -2.066</td> <td>    1.777</td>
</tr>
<tr>
  <th>x39</th>   <td>   18.2864</td> <td>   29.504</td> <td>    0.620</td> <td> 0.535</td> <td>  -39.544</td> <td>   76.117</td>
</tr>
<tr>
  <th>x40</th>   <td>   19.1531</td> <td>   32.093</td> <td>    0.597</td> <td> 0.551</td> <td>  -43.752</td> <td>   82.059</td>
</tr>
<tr>
  <th>x41</th>   <td>  -12.4987</td> <td>    4.016</td> <td>   -3.112</td> <td> 0.002</td> <td>  -20.370</td> <td>   -4.627</td>
</tr>
<tr>
  <th>x42</th>   <td>   -7.3676</td> <td>    5.377</td> <td>   -1.370</td> <td> 0.171</td> <td>  -17.907</td> <td>    3.172</td>
</tr>
<tr>
  <th>x43</th>   <td>   -0.5631</td> <td>    1.007</td> <td>   -0.559</td> <td> 0.576</td> <td>   -2.537</td> <td>    1.411</td>
</tr>
<tr>
  <th>x44</th>   <td>    0.1410</td> <td>    0.079</td> <td>    1.785</td> <td> 0.074</td> <td>   -0.014</td> <td>    0.296</td>
</tr>
<tr>
  <th>x45</th>   <td>    2.6202</td> <td>    0.349</td> <td>    7.515</td> <td> 0.000</td> <td>    1.937</td> <td>    3.304</td>
</tr>
<tr>
  <th>x46</th>   <td>   -0.7095</td> <td>    0.269</td> <td>   -2.638</td> <td> 0.008</td> <td>   -1.237</td> <td>   -0.182</td>
</tr>
<tr>
  <th>x47</th>   <td>   14.8862</td> <td>    6.398</td> <td>    2.327</td> <td> 0.020</td> <td>    2.346</td> <td>   27.427</td>
</tr>
<tr>
  <th>x48</th>   <td>    1.7138</td> <td>    7.105</td> <td>    0.241</td> <td> 0.809</td> <td>  -12.213</td> <td>   15.641</td>
</tr>
<tr>
  <th>x49</th>   <td>   -4.8835</td> <td>    1.044</td> <td>   -4.676</td> <td> 0.000</td> <td>   -6.931</td> <td>   -2.836</td>
</tr>
<tr>
  <th>x50</th>   <td>    2.9944</td> <td>    1.512</td> <td>    1.980</td> <td> 0.048</td> <td>    0.031</td> <td>    5.958</td>
</tr>
<tr>
  <th>x51</th>   <td>  -15.1452</td> <td>    5.540</td> <td>   -2.734</td> <td> 0.006</td> <td>  -26.004</td> <td>   -4.287</td>
</tr>
<tr>
  <th>x52</th>   <td>-1.182e-10</td> <td> 4.83e-10</td> <td>   -0.245</td> <td> 0.807</td> <td>-1.06e-09</td> <td> 8.28e-10</td>
</tr>
<tr>
  <th>x53</th>   <td>    8.2441</td> <td>   13.453</td> <td>    0.613</td> <td> 0.540</td> <td>  -18.126</td> <td>   34.614</td>
</tr>
<tr>
  <th>x54</th>   <td>   86.9426</td> <td>  321.342</td> <td>    0.271</td> <td> 0.787</td> <td> -542.920</td> <td>  716.805</td>
</tr>
<tr>
  <th>x55</th>   <td> -105.9596</td> <td>  360.484</td> <td>   -0.294</td> <td> 0.769</td> <td> -812.544</td> <td>  600.625</td>
</tr>
<tr>
  <th>x56</th>   <td>   89.3853</td> <td>   42.836</td> <td>    2.087</td> <td> 0.037</td> <td>    5.422</td> <td>  173.349</td>
</tr>
<tr>
  <th>x57</th>   <td>   44.2759</td> <td>   61.352</td> <td>    0.722</td> <td> 0.471</td> <td>  -75.981</td> <td>  164.533</td>
</tr>
<tr>
  <th>x58</th>   <td>    0.1447</td> <td>    1.103</td> <td>    0.131</td> <td> 0.896</td> <td>   -2.017</td> <td>    2.307</td>
</tr>
<tr>
  <th>x59</th>   <td>    1.0061</td> <td>    0.954</td> <td>    1.054</td> <td> 0.292</td> <td>   -0.865</td> <td>    2.877</td>
</tr>
<tr>
  <th>x60</th>   <td>   -5.9934</td> <td>   21.479</td> <td>   -0.279</td> <td> 0.780</td> <td>  -48.095</td> <td>   36.108</td>
</tr>
<tr>
  <th>x61</th>   <td>    5.8283</td> <td>   24.149</td> <td>    0.241</td> <td> 0.809</td> <td>  -41.507</td> <td>   53.163</td>
</tr>
<tr>
  <th>x62</th>   <td>    2.8903</td> <td>    3.350</td> <td>    0.863</td> <td> 0.388</td> <td>   -3.675</td> <td>    9.456</td>
</tr>
<tr>
  <th>x63</th>   <td>    3.8508</td> <td>    4.730</td> <td>    0.814</td> <td> 0.416</td> <td>   -5.420</td> <td>   13.121</td>
</tr>
<tr>
  <th>x64</th>   <td>  -16.6488</td> <td>    4.196</td> <td>   -3.967</td> <td> 0.000</td> <td>  -24.874</td> <td>   -8.424</td>
</tr>
<tr>
  <th>x65</th>   <td>  177.4266</td> <td>   99.436</td> <td>    1.784</td> <td> 0.074</td> <td>  -17.478</td> <td>  372.331</td>
</tr>
<tr>
  <th>x66</th>   <td> -327.3872</td> <td>  111.723</td> <td>   -2.930</td> <td> 0.003</td> <td> -546.376</td> <td> -108.399</td>
</tr>
<tr>
  <th>x67</th>   <td>  182.2881</td> <td>   14.743</td> <td>   12.364</td> <td> 0.000</td> <td>  153.390</td> <td>  211.186</td>
</tr>
<tr>
  <th>x68</th>   <td>  -14.7536</td> <td>   20.919</td> <td>   -0.705</td> <td> 0.481</td> <td>  -55.757</td> <td>   26.250</td>
</tr>
<tr>
  <th>x69</th>   <td>  -52.0472</td> <td>   71.177</td> <td>   -0.731</td> <td> 0.465</td> <td> -191.562</td> <td>   87.467</td>
</tr>
<tr>
  <th>x70</th>   <td>   62.3664</td> <td>   79.334</td> <td>    0.786</td> <td> 0.432</td> <td>  -93.136</td> <td>  217.869</td>
</tr>
<tr>
  <th>x71</th>   <td>  -17.1516</td> <td>    9.734</td> <td>   -1.762</td> <td> 0.078</td> <td>  -36.230</td> <td>    1.927</td>
</tr>
<tr>
  <th>x72</th>   <td>  -91.6947</td> <td>   15.635</td> <td>   -5.865</td> <td> 0.000</td> <td> -122.342</td> <td>  -61.048</td>
</tr>
<tr>
  <th>x73</th>   <td> -435.5407</td> <td>   39.880</td> <td>  -10.921</td> <td> 0.000</td> <td> -513.709</td> <td> -357.372</td>
</tr>
<tr>
  <th>x74</th>   <td> -395.4048</td> <td>  247.880</td> <td>   -1.595</td> <td> 0.111</td> <td> -881.275</td> <td>   90.465</td>
</tr>
<tr>
  <th>x75</th>   <td>  165.5110</td> <td>  300.640</td> <td>    0.551</td> <td> 0.582</td> <td> -423.774</td> <td>  754.796</td>
</tr>
<tr>
  <th>x76</th>   <td>   94.8156</td> <td>  284.153</td> <td>    0.334</td> <td> 0.739</td> <td> -462.153</td> <td>  651.784</td>
</tr>
<tr>
  <th>x77</th>   <td>  133.3275</td> <td>  336.596</td> <td>    0.396</td> <td> 0.692</td> <td> -526.434</td> <td>  793.089</td>
</tr>
<tr>
  <th>x78</th>   <td>  195.9651</td> <td>   54.599</td> <td>    3.589</td> <td> 0.000</td> <td>   88.945</td> <td>  302.985</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>3803.577</td> <th>  Durbin-Watson:     </th> <td>   0.621</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>8630.456</td>
</tr>
<tr>
  <th>Skew:</th>           <td> 1.246</td>  <th>  Prob(JB):          </th> <td>    0.00</td>
</tr>
<tr>
  <th>Kurtosis:</th>       <td> 5.390</td>  <th>  Cond. No.          </th> <td>1.24e+16</td>
</tr>
</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.64e-24. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular.</p>

<h3 id="feature-names">Feature Names?</h3>

<p>The <code>interaction</code> object keeps track of the names of our feature combinations&hellip; sort of</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">print</span><span class="p">(</span><span class="n">interaction</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">())</span></code></pre></div>
<pre><code>['x0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10', 'x11', 'x0 x1', 'x0 x2', 'x0 x3', 'x0 x4', 'x0 x5', 'x0 x6', 'x0 x7', 'x0 x8', 'x0 x9', 'x0 x10', 'x0 x11', 'x1 x2', 'x1 x3', 'x1 x4', 'x1 x5', 'x1 x6', 'x1 x7', 'x1 x8', 'x1 x9', 'x1 x10', 'x1 x11', 'x2 x3', 'x2 x4', 'x2 x5', 'x2 x6', 'x2 x7', 'x2 x8', 'x2 x9', 'x2 x10', 'x2 x11', 'x3 x4', 'x3 x5', 'x3 x6', 'x3 x7', 'x3 x8', 'x3 x9', 'x3 x10', 'x3 x11', 'x4 x5', 'x4 x6', 'x4 x7', 'x4 x8', 'x4 x9', 'x4 x10', 'x4 x11', 'x5 x6', 'x5 x7', 'x5 x8', 'x5 x9', 'x5 x10', 'x5 x11', 'x6 x7', 'x6 x8', 'x6 x9', 'x6 x10', 'x6 x11', 'x7 x8', 'x7 x9', 'x7 x10', 'x7 x11', 'x8 x9', 'x8 x10', 'x8 x11', 'x9 x10', 'x9 x11', 'x10 x11']
</code></pre>

<p>Assuming that a bevy of <code>xi xj</code>s aren&rsquo;t much more useful than the output of <code>model.summary()</code> we can do some hacky, Python nonsense to decode a bit.</p>

<p>For starters, we want to create a dictionary that maps <code>xi</code> to its corresponding feature name in our dataset.</p>

<p>We&rsquo;ll use the <code>itertools.count()</code> function, as it&rsquo;s basically <code>enumerate</code>, but plays better with generator expressions.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">count</span>

<span class="n">x_to_feature</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">((</span><span class="s1">&#39;x{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">count</span><span class="p">()),</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">))</span>
<span class="n">x_to_feature</span></code></pre></div>
<pre><code>{'x0': 'season',
 'x1': 'year',
 'x2': 'month',
 'x3': 'hour',
 'x4': 'holiday',
 'x5': 'weekday',
 'x6': 'workingday',
 'x7': 'weather',
 'x8': 'temp',
 'x9': 'feelslike',
 'x10': 'humidity',
 'x11': 'windspeed'}
</code></pre>

<p>Next, you know it&rsquo;s Sound Data Science™ when we break out</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">re</span></code></pre></div>
<p>Finally, this <a href="https://www.youtube.com/watch?v=9VBSH-2fMuw">little diddy</a> goes through and makes the appropriate substitutions for <code>xi</code> to their respective feature names, then replaces spaces with underscores so <code>pandas</code> references isn&rsquo;t such a chore</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># necessary so `x11` gets a chance to swap before </span>
<span class="c1"># before `x1` leaves us with &#34;season1&#34; where we wanted</span>
<span class="c1"># &#34;windspeed&#34;</span>
<span class="n">feature_keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">x_to_feature</span><span class="o">.</span><span class="n">keys</span><span class="p">())[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="n">features</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">interaction</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">feature_keys</span><span class="p">:</span>
        <span class="n">feature_name</span> <span class="o">=</span> <span class="n">x_to_feature</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="n">feature</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">feature_name</span><span class="p">,</span> <span class="n">feature</span><span class="p">)</span>
    <span class="n">feature</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="s1">&#39;_&#39;</span><span class="p">,</span> <span class="n">feature</span><span class="p">)</span>
    <span class="n">features</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">feature</span><span class="p">)</span></code></pre></div>
<p>Then we&rsquo;ll slap these feature names onto our big ol&rsquo; dataset</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="kn">as</span> <span class="nn">sm</span>

<span class="n">X_all_inter</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_inter</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">features</span><span class="p">)</span>
<span class="n">X_all_inter_const</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">X_all_inter</span><span class="p">)</span></code></pre></div>
<p>And refit</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">model</span> <span class="o">=</span> <span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">X_all_inter_const</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span></code></pre></div>
<p><table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>         <td>riders</td>      <th>  R-squared:         </th>  <td>   0.449</td><br />
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.447</td><br />
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   183.2</td><br />
</tr>
<tr>
  <th>Date:</th>             <td>Thu, 12 Sep 2019</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td><br />
</tr>
<tr>
  <th>Time:</th>                 <td>12:39:27</td>     <th>  Log-Likelihood:    </th> <td>-1.0986e+05</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td> 17379</td>      <th>  AIC:               </th>  <td>2.199e+05</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td> 17301</td>      <th>  BIC:               </th>  <td>2.205e+05</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>    77</td>      <th>                     </th>      <td> </td><br />
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td><br />
</tr>
</table>
<table class="simpletable">
<tr>
            <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P&gt;|t|</th>  <th>[0.025</th>    <th>0.975]</th><br />
</tr>
<tr>
  <th>const</th>                <td>  -12.9215</td> <td>   31.348</td> <td>   -0.412</td> <td> 0.680</td> <td>  -74.367</td> <td>   48.524</td>
</tr>
<tr>
  <th>season</th>               <td>    4.8668</td> <td>   13.591</td> <td>    0.358</td> <td> 0.720</td> <td>  -21.773</td> <td>   31.506</td>
</tr>
<tr>
  <th>year</th>                 <td>    1.5025</td> <td>   13.709</td> <td>    0.110</td> <td> 0.913</td> <td>  -25.368</td> <td>   28.373</td>
</tr>
<tr>
  <th>month</th>                <td>   -5.6567</td> <td>    3.650</td> <td>   -1.550</td> <td> 0.121</td> <td>  -12.811</td> <td>    1.497</td>
</tr>
<tr>
  <th>hour</th>                 <td>   -1.5711</td> <td>    1.010</td> <td>   -1.555</td> <td> 0.120</td> <td>   -3.551</td> <td>    0.409</td>
</tr>
<tr>
  <th>holiday</th>              <td>  -53.5016</td> <td>   42.280</td> <td>   -1.265</td> <td> 0.206</td> <td> -136.374</td> <td>   29.371</td>
</tr>
<tr>
  <th>weekday</th>              <td>   -5.8416</td> <td>    3.221</td> <td>   -1.814</td> <td> 0.070</td> <td>  -12.155</td> <td>    0.471</td>
</tr>
<tr>
  <th>workingday</th>           <td>  -59.3405</td> <td>   14.670</td> <td>   -4.045</td> <td> 0.000</td> <td>  -88.095</td> <td>  -30.586</td>
</tr>
<tr>
  <th>weather</th>              <td>   24.8815</td> <td>   12.260</td> <td>    2.030</td> <td> 0.042</td> <td>    0.851</td> <td>   48.912</td>
</tr>
<tr>
  <th>temp</th>                 <td>  967.3801</td> <td>  242.465</td> <td>    3.990</td> <td> 0.000</td> <td>  492.123</td> <td> 1442.637</td>
</tr>
<tr>
  <th>feelslike</th>            <td> -398.7968</td> <td>  267.389</td> <td>   -1.491</td> <td> 0.136</td> <td> -922.906</td> <td>  125.313</td>
</tr>
<tr>
  <th>humidity</th>             <td>   29.5847</td> <td>   38.027</td> <td>    0.778</td> <td> 0.437</td> <td>  -44.953</td> <td>  104.122</td>
</tr>
<tr>
  <th>windspeed</th>            <td> -174.6887</td> <td>   55.839</td> <td>   -3.128</td> <td> 0.002</td> <td> -284.138</td> <td>  -65.239</td>
</tr>
<tr>
  <th>season_year</th>          <td>   -2.0902</td> <td>    3.782</td> <td>   -0.553</td> <td> 0.580</td> <td>   -9.503</td> <td>    5.322</td>
</tr>
<tr>
  <th>season_month</th>         <td>    1.9024</td> <td>    0.528</td> <td>    3.600</td> <td> 0.000</td> <td>    0.867</td> <td>    2.938</td>
</tr>
<tr>
  <th>season_hour</th>          <td>    0.7962</td> <td>    0.259</td> <td>    3.071</td> <td> 0.002</td> <td>    0.288</td> <td>    1.304</td>
</tr>
<tr>
  <th>season_holiday</th>       <td>   10.7146</td> <td>    8.522</td> <td>    1.257</td> <td> 0.209</td> <td>   -5.990</td> <td>   27.419</td>
</tr>
<tr>
  <th>season_weekday</th>       <td>    0.8804</td> <td>    0.890</td> <td>    0.989</td> <td> 0.323</td> <td>   -0.864</td> <td>    2.625</td>
</tr>
<tr>
  <th>season_workingday</th>    <td>   -3.3540</td> <td>    3.979</td> <td>   -0.843</td> <td> 0.399</td> <td>  -11.152</td> <td>    4.444</td>
</tr>
<tr>
  <th>season_weather</th>       <td>    5.1034</td> <td>    3.100</td> <td>    1.646</td> <td> 0.100</td> <td>   -0.972</td> <td>   11.179</td>
</tr>
<tr>
  <th>season_temp</th>          <td> -224.2428</td> <td>   86.181</td> <td>   -2.602</td> <td> 0.009</td> <td> -393.166</td> <td>  -55.320</td>
</tr>
<tr>
  <th>season_feelslike</th>     <td>  175.4640</td> <td>   94.973</td> <td>    1.848</td> <td> 0.065</td> <td>  -10.693</td> <td>  361.621</td>
</tr>
<tr>
  <th>season_humidity</th>      <td>  -20.6737</td> <td>   12.747</td> <td>   -1.622</td> <td> 0.105</td> <td>  -45.659</td> <td>    4.312</td>
</tr>
<tr>
  <th>season_windspeed</th>     <td>   27.4909</td> <td>   16.320</td> <td>    1.685</td> <td> 0.092</td> <td>   -4.497</td> <td>   59.479</td>
</tr>
<tr>
  <th>year_month</th>           <td>    2.0389</td> <td>    1.193</td> <td>    1.709</td> <td> 0.087</td> <td>   -0.299</td> <td>    4.377</td>
</tr>
<tr>
  <th>year_hour</th>            <td>    2.7809</td> <td>    0.318</td> <td>    8.752</td> <td> 0.000</td> <td>    2.158</td> <td>    3.404</td>
</tr>
<tr>
  <th>year_holiday</th>         <td>  -10.2711</td> <td>   13.890</td> <td>   -0.739</td> <td> 0.460</td> <td>  -37.497</td> <td>   16.955</td>
</tr>
<tr>
  <th>year_weekday</th>         <td>    3.0712</td> <td>    1.047</td> <td>    2.932</td> <td> 0.003</td> <td>    1.018</td> <td>    5.124</td>
</tr>
<tr>
  <th>year_workingday</th>      <td>   18.9473</td> <td>    4.631</td> <td>    4.092</td> <td> 0.000</td> <td>    9.870</td> <td>   28.024</td>
</tr>
<tr>
  <th>year_weather</th>         <td>    1.8761</td> <td>    3.686</td> <td>    0.509</td> <td> 0.611</td> <td>   -5.349</td> <td>    9.101</td>
</tr>
<tr>
  <th>year_temp</th>            <td> -157.1947</td> <td>   81.641</td> <td>   -1.925</td> <td> 0.054</td> <td> -317.219</td> <td>    2.830</td>
</tr>
<tr>
  <th>year_feelslike</th>       <td>  281.8987</td> <td>   91.747</td> <td>    3.073</td> <td> 0.002</td> <td>  102.066</td> <td>  461.731</td>
</tr>
<tr>
  <th>year_humidity</th>        <td>  -86.9838</td> <td>   13.435</td> <td>   -6.475</td> <td> 0.000</td> <td> -113.317</td> <td>  -60.650</td>
</tr>
<tr>
  <th>year_windspeed</th>       <td>   56.9213</td> <td>   18.839</td> <td>    3.021</td> <td> 0.003</td> <td>   19.995</td> <td>   93.848</td>
</tr>
<tr>
  <th>month_hour</th>           <td>   -0.1121</td> <td>    0.081</td> <td>   -1.390</td> <td> 0.165</td> <td>   -0.270</td> <td>    0.046</td>
</tr>
<tr>
  <th>month_holiday</th>        <td>   -2.2869</td> <td>    2.442</td> <td>   -0.937</td> <td> 0.349</td> <td>   -7.073</td> <td>    2.499</td>
</tr>
<tr>
  <th>month_weekday</th>        <td>   -0.2278</td> <td>    0.277</td> <td>   -0.823</td> <td> 0.410</td> <td>   -0.770</td> <td>    0.314</td>
</tr>
<tr>
  <th>month_workingday</th>     <td>    1.5086</td> <td>    1.241</td> <td>    1.215</td> <td> 0.224</td> <td>   -0.924</td> <td>    3.942</td>
</tr>
<tr>
  <th>month_weather</th>        <td>   -0.1445</td> <td>    0.980</td> <td>   -0.147</td> <td> 0.883</td> <td>   -2.066</td> <td>    1.777</td>
</tr>
<tr>
  <th>month_temp</th>           <td>   18.2864</td> <td>   29.504</td> <td>    0.620</td> <td> 0.535</td> <td>  -39.544</td> <td>   76.117</td>
</tr>
<tr>
  <th>month_feelslike</th>      <td>   19.1531</td> <td>   32.093</td> <td>    0.597</td> <td> 0.551</td> <td>  -43.752</td> <td>   82.059</td>
</tr>
<tr>
  <th>month_humidity</th>       <td>  -12.4987</td> <td>    4.016</td> <td>   -3.112</td> <td> 0.002</td> <td>  -20.370</td> <td>   -4.627</td>
</tr>
<tr>
  <th>month_windspeed</th>      <td>   -7.3676</td> <td>    5.377</td> <td>   -1.370</td> <td> 0.171</td> <td>  -17.907</td> <td>    3.172</td>
</tr>
<tr>
  <th>hour_holiday</th>         <td>   -0.5631</td> <td>    1.007</td> <td>   -0.559</td> <td> 0.576</td> <td>   -2.537</td> <td>    1.411</td>
</tr>
<tr>
  <th>hour_weekday</th>         <td>    0.1410</td> <td>    0.079</td> <td>    1.785</td> <td> 0.074</td> <td>   -0.014</td> <td>    0.296</td>
</tr>
<tr>
  <th>hour_workingday</th>      <td>    2.6202</td> <td>    0.349</td> <td>    7.515</td> <td> 0.000</td> <td>    1.937</td> <td>    3.304</td>
</tr>
<tr>
  <th>hour_weather</th>         <td>   -0.7095</td> <td>    0.269</td> <td>   -2.638</td> <td> 0.008</td> <td>   -1.237</td> <td>   -0.182</td>
</tr>
<tr>
  <th>hour_temp</th>            <td>   14.8862</td> <td>    6.398</td> <td>    2.327</td> <td> 0.020</td> <td>    2.346</td> <td>   27.427</td>
</tr>
<tr>
  <th>hour_feelslike</th>       <td>    1.7138</td> <td>    7.105</td> <td>    0.241</td> <td> 0.809</td> <td>  -12.213</td> <td>   15.641</td>
</tr>
<tr>
  <th>hour_humidity</th>        <td>   -4.8835</td> <td>    1.044</td> <td>   -4.676</td> <td> 0.000</td> <td>   -6.931</td> <td>   -2.836</td>
</tr>
<tr>
  <th>hour_windspeed</th>       <td>    2.9944</td> <td>    1.512</td> <td>    1.980</td> <td> 0.048</td> <td>    0.031</td> <td>    5.958</td>
</tr>
<tr>
  <th>holiday_weekday</th>      <td>  -15.1452</td> <td>    5.540</td> <td>   -2.734</td> <td> 0.006</td> <td>  -26.004</td> <td>   -4.287</td>
</tr>
<tr>
  <th>holiday_workingday</th>   <td>-1.182e-10</td> <td> 4.83e-10</td> <td>   -0.245</td> <td> 0.807</td> <td>-1.06e-09</td> <td> 8.28e-10</td>
</tr>
<tr>
  <th>holiday_weather</th>      <td>    8.2441</td> <td>   13.453</td> <td>    0.613</td> <td> 0.540</td> <td>  -18.126</td> <td>   34.614</td>
</tr>
<tr>
  <th>holiday_temp</th>         <td>   86.9426</td> <td>  321.342</td> <td>    0.271</td> <td> 0.787</td> <td> -542.920</td> <td>  716.805</td>
</tr>
<tr>
  <th>holiday_feelslike</th>    <td> -105.9596</td> <td>  360.484</td> <td>   -0.294</td> <td> 0.769</td> <td> -812.544</td> <td>  600.625</td>
</tr>
<tr>
  <th>holiday_humidity</th>     <td>   89.3853</td> <td>   42.836</td> <td>    2.087</td> <td> 0.037</td> <td>    5.422</td> <td>  173.349</td>
</tr>
<tr>
  <th>holiday_windspeed</th>    <td>   44.2759</td> <td>   61.352</td> <td>    0.722</td> <td> 0.471</td> <td>  -75.981</td> <td>  164.533</td>
</tr>
<tr>
  <th>weekday_workingday</th>   <td>    0.1447</td> <td>    1.103</td> <td>    0.131</td> <td> 0.896</td> <td>   -2.017</td> <td>    2.307</td>
</tr>
<tr>
  <th>weekday_weather</th>      <td>    1.0061</td> <td>    0.954</td> <td>    1.054</td> <td> 0.292</td> <td>   -0.865</td> <td>    2.877</td>
</tr>
<tr>
  <th>weekday_temp</th>         <td>   -5.9934</td> <td>   21.479</td> <td>   -0.279</td> <td> 0.780</td> <td>  -48.095</td> <td>   36.108</td>
</tr>
<tr>
  <th>weekday_feelslike</th>    <td>    5.8283</td> <td>   24.149</td> <td>    0.241</td> <td> 0.809</td> <td>  -41.507</td> <td>   53.163</td>
</tr>
<tr>
  <th>weekday_humidity</th>     <td>    2.8903</td> <td>    3.350</td> <td>    0.863</td> <td> 0.388</td> <td>   -3.675</td> <td>    9.456</td>
</tr>
<tr>
  <th>weekday_windspeed</th>    <td>    3.8508</td> <td>    4.730</td> <td>    0.814</td> <td> 0.416</td> <td>   -5.420</td> <td>   13.121</td>
</tr>
<tr>
  <th>workingday_weather</th>   <td>  -16.6488</td> <td>    4.196</td> <td>   -3.967</td> <td> 0.000</td> <td>  -24.874</td> <td>   -8.424</td>
</tr>
<tr>
  <th>workingday_temp</th>      <td>  177.4266</td> <td>   99.436</td> <td>    1.784</td> <td> 0.074</td> <td>  -17.478</td> <td>  372.331</td>
</tr>
<tr>
  <th>workingday_feelslike</th> <td> -327.3872</td> <td>  111.723</td> <td>   -2.930</td> <td> 0.003</td> <td> -546.376</td> <td> -108.399</td>
</tr>
<tr>
  <th>workingday_humidity</th>  <td>  182.2881</td> <td>   14.743</td> <td>   12.364</td> <td> 0.000</td> <td>  153.390</td> <td>  211.186</td>
</tr>
<tr>
  <th>workingday_windspeed</th> <td>  -14.7536</td> <td>   20.919</td> <td>   -0.705</td> <td> 0.481</td> <td>  -55.757</td> <td>   26.250</td>
</tr>
<tr>
  <th>weather_temp</th>         <td>  -52.0472</td> <td>   71.177</td> <td>   -0.731</td> <td> 0.465</td> <td> -191.562</td> <td>   87.467</td>
</tr>
<tr>
  <th>weather_feelslike</th>    <td>   62.3664</td> <td>   79.334</td> <td>    0.786</td> <td> 0.432</td> <td>  -93.136</td> <td>  217.869</td>
</tr>
<tr>
  <th>weather_humidity</th>     <td>  -17.1516</td> <td>    9.734</td> <td>   -1.762</td> <td> 0.078</td> <td>  -36.230</td> <td>    1.927</td>
</tr>
<tr>
  <th>weather_windspeed</th>    <td>  -91.6947</td> <td>   15.635</td> <td>   -5.865</td> <td> 0.000</td> <td> -122.342</td> <td>  -61.048</td>
</tr>
<tr>
  <th>temp_feelslike</th>       <td> -435.5407</td> <td>   39.880</td> <td>  -10.921</td> <td> 0.000</td> <td> -513.709</td> <td> -357.372</td>
</tr>
<tr>
  <th>temp_humidity</th>        <td> -395.4048</td> <td>  247.880</td> <td>   -1.595</td> <td> 0.111</td> <td> -881.275</td> <td>   90.465</td>
</tr>
<tr>
  <th>temp_windspeed</th>       <td>  165.5110</td> <td>  300.640</td> <td>    0.551</td> <td> 0.582</td> <td> -423.774</td> <td>  754.796</td>
</tr>
<tr>
  <th>feelslike_humidity</th>   <td>   94.8156</td> <td>  284.153</td> <td>    0.334</td> <td> 0.739</td> <td> -462.153</td> <td>  651.784</td>
</tr>
<tr>
  <th>feelslike_windspeed</th>  <td>  133.3275</td> <td>  336.596</td> <td>    0.396</td> <td> 0.692</td> <td> -526.434</td> <td>  793.089</td>
</tr>
<tr>
  <th>humidity_windspeed</th>   <td>  195.9651</td> <td>   54.599</td> <td>    3.589</td> <td> 0.000</td> <td>   88.945</td> <td>  302.985</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>3803.577</td> <th>  Durbin-Watson:     </th> <td>   0.621</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>8630.456</td>
</tr>
<tr>
  <th>Skew:</th>           <td> 1.246</td>  <th>  Prob(JB):          </th> <td>    0.00</td>
</tr>
<tr>
  <th>Kurtosis:</th>       <td> 5.390</td>  <th>  Cond. No.          </th> <td>1.24e+16</td>
</tr>
</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.64e-24. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular.</p>

<h3 id="and-that-s-data-science">And that&rsquo;s Data Science!</h3>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="n">Image</span><span class="p">(</span><span class="s1">&#39;images/we_did_it.jpg&#39;</span><span class="p">)</span></code></pre></div>
<p><img src="interaction_terms_37_0.jpeg" alt="jpeg" /></p>

</div>
  <aside>
      <div class="bug_reporting">
          <h4>Find an error or bug?</h4>
          <p>Everything on this site is available on GitHub. Head to <a href='https://github.com/napsterinblue/notes/issues/new'>and submit a suggested change</a>. You can also message me directly on <a href='https://twitter.com/napsterinblue'>Twitter</a>.</p>
      </div>
      </aside>

    </div>
</article>




            </div>

        </div>
    </div>

    

    <footer class="footer text-center">
        <div class="container">
            <span class="text-muted">This project contains 179 pages and is available on <a href="https://github.com/napsterinblue/notes">GitHub</a>. Copyright &copy; NapsterInBlue, <time datetime="2018">2018</time>.</span>
        </div>
    </footer>

    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
        crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.3/umd/popper.min.js" integrity="sha384-vFJXuSJphROIrBnz7yo7oB41mKfc8JzQZiCq4NCceLEaO4IHwicKwpJf9c9IpFgh"
        crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/js/bootstrap.min.js" integrity="sha384-alpBpkh1PFOepccYVYDB4do5UnbKysX5WZXm3XxPqe5iKTfUKjNkCk9SaVuEZflJ"
        crossorigin="anonymous"></script>

</body>

</html>
